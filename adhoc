import pandas as pd
from tqdm import tqdm

list_col = ['Unique_DEA', 'Unique_DMN', 'Unique_DMA','Unique_DEN', 'Unique_DEM', 'Unique_DNA', 
            'DNM_MISS', 'DNE_MISS','DAM_MISS', 'DAN_MISS', 'DAE_MISS']

# Initialize global dicts
global_index_to_cluster = {}
value_to_clusterid = {}

# Load existing data
existing_df = df1[df1['CLUSTER_ID'] != -1]

# Build global dictionaries from existing data
for idx, row in existing_df.iterrows():
    cluster_id = row['CLUSTER_ID']
    global_index_to_cluster[idx] = cluster_id
    for col in list_col:
        val = row[col]
        if pd.notna(val):
            if val not in value_to_clusterid:
                value_to_clusterid[val] = set()
            value_to_clusterid[val].add(cluster_id)

# Start cluster_counter from max existing cluster id + 1
if existing_df['CLUSTER_ID'].max() > 0:
    cluster_counter = existing_df['CLUSTER_ID'].max() + 1
else:
    cluster_counter = 1

# Prepare conflict record list
conflict_records = []

# Process new data
new_df = df1[df1['CLUSTER_ID'] == -1]

# Process new data per group (DOB_X or you can skip groupby if not needed)
for key, group in tqdm(new_df.groupby("DOB_X")):
    for idx, row in group.iterrows():
        matched_clusters = set()
        
        # Find existing cluster ids matching any value in this row
        for col in list_col:
            val = row[col]
            if pd.notna(val) and val in value_to_clusterid:
                matched_clusters.update(value_to_clusterid[val])
        
        # Decide cluster_id assignment
        if not matched_clusters:
            # No match → assign new cluster_id
            assigned_cluster = cluster_counter
            cluster_counter += 1
        else:
            # Match found → pick first cluster_id
            assigned_cluster = min(matched_clusters)
            
            # If conflict (more than 1 cluster_id matched), record conflict
            if len(matched_clusters) > 1:
                conflict_records.append({
                    'new_data_index': idx,
                    'new_data_policy_number': row['CUST_ID'],  # Replace with your root policy column name
                    'matched_existing_cluster_ids': list(sorted(matched_clusters)),
                    'assigned_cluster_id': assigned_cluster
                })
        
        # Update global index → cluster_id mapping
        global_index_to_cluster[idx] = assigned_cluster
        
        # Update value_to_clusterid with current row values
        for col in list_col:
            val = row[col]
            if pd.notna(val):
                if val not in value_to_clusterid:
                    value_to_clusterid[val] = set()
                value_to_clusterid[val].add(assigned_cluster)

# Final update of df1
df1.loc[list(global_index_to_cluster.keys()), 'CLUSTER_ID'] = list(global_index_to_cluster.values())

# Build df_conflict
df_conflict = pd.DataFrame(conflict_records)

# Optional: Show how many conflicts were detected
print(f"Conflicts detected: {len(df_conflict)}")
