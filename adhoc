import pandas as pd
from collections import defaultdict

# ── Inputs ─────────────────────────────────────────────────────────────────────
# df: your full DataFrame, with columns:
#   - "DOB_X"
#   - "unique_number_combined" (old clusters ≠ -1; new = -1)
#   - "CUST_ID"
#   - the 11 Unique_* / *_MISS columns below
#
# df_pl and max_value are just used to seed your counter; adapt as needed.

counter =
    int(df_pl["unique_number_combined"].max()

keys = [
    'Unique_DEA', 'Unique_DMN', 'Unique_DMA', 'Unique_DEN',
    'Unique_DEM', 'Unique_DNA', 'DNM_MISS', 'DNE_MISS',
    'DAM_MISS', 'DAN_MISS', 'DAE_MISS'
]

# ── Prep storage ───────────────────────────────────────────────────────────────
conflicts = []            # list of dicts you’ll turn into df_conflict
updates   = {}            # idx → newly assigned cluster for new rows

# ── Union-Find (Disjoint-Set) Helpers ─────────────────────────────────────────
parent = {}
def find(i):
    parent.setdefault(i, i)
    if parent[i] != i:
        parent[i] = find(parent[i])
    return parent[i]

def union(i, j):
    ri, rj = find(i), find(j)
    if ri != rj:
        parent[rj] = ri

# ── Main Loop: per-DOB grouping ────────────────────────────────────────────────
for dob, grp in df.groupby("DOB_X"):
    idxs = grp.index.tolist()

    # 1) Build inverted index value → [indices] within this DOB
    val_map = defaultdict(list)
    for k in keys:
        for i, v in grp[k].items():
            if pd.notna(v):
                val_map[v].append(i)

    # 2) Union all rows sharing any single value
    for lst in val_map.values():
        first = lst[0]
        for other in lst[1:]:
            union(first, other)

    # 3) Collect connected components
    comps = defaultdict(list)
    for i in idxs:
        comps[find(i)].append(i)

    # 4) For each component, decide & assign cluster
    for comp in comps.values():
        # old cluster IDs present in this component
        old_cids = {
            df.at[i, "unique_number_combined"]
            for i in comp
            if df.at[i, "unique_number_combined"] != -1
        }
        # new-row indices in this component
        new_idxs = [i for i in comp if df.at[i, "unique_number_combined"] == -1]

        # choose assigned cluster
        if old_cids:
            assigned = min(old_cids)
        else:
            assigned = counter
            counter += 1

        # record assignment for each new row
        for i in new_idxs:
            updates[i] = assigned

        # **only** log if it's truly a conflict **and** involves new rows
        if len(old_cids) > 1 and new_idxs:
            for i in new_idxs:
                conflicts.append({
                    "ROOT_POLICY_NUMBER":   df.at[i, "CUST_ID"],
                    "matched_index":        i,
                    "matched_clusters":     sorted(old_cids),
                    "assigned_cluster_id":  assigned
                })

# ── Apply updates back to df ─────────────────────────────────────────────────
for i, cid in updates.items():
    df.at[i, "unique_number_combined"] = cid

# ── Build the conflict DataFrame ───────────────────────────────────────────────
df_conflict = pd.DataFrame(conflicts).drop_duplicates().reset_index(drop=True)

# ── Now df has all new rows clustered, old clusters untouched,
#     and df_conflict lists only true new-row conflicts. ────────────────────────
